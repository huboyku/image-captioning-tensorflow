# ğŸ–¼ï¸ Image Captioning with CNNâ€“LSTM (TensorFlow)

> Generate natural language captions for images using a deep learning pipeline that combines a **CNN encoder** (InceptionV3) and an **LSTM decoder**.  
> This project replicates the structure of modern image-to-text models and demonstrates a full ML workflow â€” from data preprocessing to model training and evaluation.

---

### ğŸ§  Tech Stack

![Python](https://img.shields.io/badge/Python-3.10-blue?logo=python)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange?logo=tensorflow)
![Keras](https://img.shields.io/badge/Keras-red?logo=keras)
![NumPy](https://img.shields.io/badge/NumPy-lightblue?logo=numpy)
![Matplotlib](https://img.shields.io/badge/Matplotlib-blue?logo=plotly)
![Colab](https://img.shields.io/badge/Google%20Colab-Notebook-yellow?logo=googlecolab)

---

## ğŸ“˜ Project Overview

This repository implements an **image captioning model** trained on the **Flickr8k dataset**.  
It combines **computer vision** and **natural language processing** techniques to describe images in plain English.

### Key Features
- ğŸ§© Modular architecture (separate data, model, and training scripts)
- ğŸ§  Encoderâ€“decoder model using CNN (InceptionV3) and LSTM
- ğŸ—‚ï¸ Clean code organization (`src/`, `utils/`, `data/`, `outputs/`)
- ğŸ“ˆ Automatic training logs and history visualization
- ğŸ” Easy reproducibility on Google Colab

---

## ğŸ§© Model Architecture

```
Image â†’ CNN Encoder (InceptionV3) â†’ Feature Vector
             â†“
         LSTM Decoder â†’ Caption Tokens â†’ Text Output
```

- **Encoder:** Extracts visual features from images using a pre-trained InceptionV3 CNN  
- **Decoder:** Generates captions word-by-word using LSTM layers  
- **Loss:** Sparse categorical cross-entropy  
- **Optimizer:** Adam  

A diagram of the model is available as `model.png`.

---

## ğŸš€ How to Run (on Google Colab)

You can reproduce the entire project easily using Google Colab:

```python
# 1ï¸âƒ£ Clone the repository
!git clone https://github.com/<your-username>/image-captioning-tensorflow.git
%cd image-captioning-tensorflow

# 2ï¸âƒ£ Install dependencies
!pip install -r requirements.txt

# 3ï¸âƒ£ Download the Flickr8k dataset (automated)
!python utils/data_downloader.py

# 4ï¸âƒ£ Run the training notebook
!jupyter nbconvert --to notebook --execute main.ipynb
```

> ğŸ’¡ *Alternatively, open `main.ipynb` directly in Colab and run all cells.*

---

## ğŸ“‚ Project Structure

```
image_captioning_project/
â”‚
â”œâ”€â”€ main.ipynb                # End-to-end notebook (data â†’ training â†’ evaluation)
â”œâ”€â”€ model.png                 # Model diagram
â”œâ”€â”€ training_history.pkl/json # Training history and metrics
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ model.py              # Defines the CNNâ€“LSTM architecture
â”‚   â”œâ”€â”€ train.py              # Training loop and checkpoint saving
â”‚   â”œâ”€â”€ evaluate.py           # Caption generation and BLEU scoring
â”‚   â”œâ”€â”€ feature_extractor.py  # Image feature extraction using InceptionV3
â”‚   â”œâ”€â”€ data_generator.py     # Custom data generator for large datasets
â”‚   â”œâ”€â”€ tokenizer_utils.py    # Tokenizer and vocabulary utilities
â”‚   â”œâ”€â”€ text_processing.py    # Caption cleaning and preprocessing
â”‚   â””â”€â”€ data_utils.py         # Data loading and split helpers
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ data_downloader.py    # Script to download and unzip Flickr8k dataset
â”‚   â””â”€â”€ file_manager.py       # Folder and file handling utilities
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ captions/             # Caption text files (Flickr8k)
â”‚   â””â”€â”€ images/               # Placeholder for image dataset
â”‚
â””â”€â”€ outputs/
    â””â”€â”€ predictions/          # Model outputs and generated captions
```

---

## ğŸ§ª Evaluation Metrics

- **BLEU score** for caption quality  
- **Training loss** and **validation accuracy** tracked over epochs  
- Visualization of learning curves from `training_history.pkl`  

---

## ğŸ“¦ Requirements

Create a `requirements.txt` (or install manually):

```
tensorflow>=2.12
numpy>=1.23
tqdm>=4.65
requests>=2.31
```

---

## ğŸ’¡ Future Improvements

- Integrate **attention mechanisms (Bahdanau / Luong)**
- Train on **Flickr30k** or **MS-COCO** for richer captions
- Deploy inference as a **Flask / Streamlit web app**
- Experiment with **Transformer-based decoders**

---

## ğŸ§‘â€ğŸ’» Author

**[Your Name]**  
ğŸ’¼ AI / ML Engineer | Deep Learning & Computer Vision  
ğŸ“« [Your LinkedIn](https://www.linkedin.com/) â€¢ [Your Portfolio](https://github.com/yourusername)

---

## ğŸ·ï¸ License

This project is licensed under the MIT License â€” feel free to use and modify for research or learning.

---

### â­ If you find this project helpful, consider giving it a star!
